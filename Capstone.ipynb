{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMItvv3AJTPmOTZk+f2XNxj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayaresponsi/Analisis-SMS-Menggunakan-AI-Tools/blob/main/Capstone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWljtnmmsygD",
        "outputId": "5b5cded2-59c1-474b-a455-f93a604830a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain-core<2.0.0,>=0.3.75 (from langchain_community)\n",
            "  Downloading langchain_core-0.3.75-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.43)\n",
            "Collecting requests<3,>=2.32.5 (from langchain_community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.6.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.16)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.6.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.6.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (0.3.9)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (0.24.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain_community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain_community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_core-0.3.75-py3-none-any.whl (443 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.0/444.0 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-core, langchain_community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.74\n",
            "    Uninstalling langchain-core-0.3.74:\n",
            "      Successfully uninstalled langchain-core-0.3.74\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-core-0.3.75 langchain_community-0.3.29 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n",
            "Collecting replicate\n",
            "  Downloading replicate-1.0.7-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from replicate) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from replicate) (25.0)\n",
            "Requirement already satisfied: pydantic>1.10.7 in /usr/local/lib/python3.12/dist-packages (from replicate) (2.11.7)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from replicate) (4.15.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.21.0->replicate) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.21.0->replicate) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.21.0->replicate) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.21.0->replicate) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.21.0->replicate) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>1.10.7->replicate) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>1.10.7->replicate) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>1.10.7->replicate) (0.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.3.1)\n",
            "Downloading replicate-1.0.7-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.6/48.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: replicate\n",
            "Successfully installed replicate-1.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_community\n",
        "!pip install replicate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import Replicate\n",
        "import os\n",
        "from google.colab import userdata\n",
        "# Set the API token\n",
        "api_token = userdata.get('REPLICATE_API_TOKEN')\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = api_token\n",
        "# Model setup\n",
        "model = \"ibm-granite/granite-3.2-8b-instruct\"\n",
        "output = Replicate(\n",
        "  model=model,\n",
        "  replicate_api_token=api_token,\n",
        ")"
      ],
      "metadata": {
        "id": "48TnxwNctxPg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV (adjust the path if needed)\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/content/spam.csv', sep='\\t', encoding='latin-1', names=['v1', 'v2'])\n",
        "\n",
        "# Sample the DataFrame to reduce the size of the input data\n",
        "sampled_df = df.sample(n=1000, random_state=42) # Sample 1000 rows for analysis\n",
        "\n",
        "# 4. Format sampled messages for Granite\n",
        "formatted_messages = \"\"\n",
        "for i, row in sampled_df.iterrows():\n",
        "    formatted_messages += f\"v1: {row['v1']} | v2: {row['v2']}\\n\"\n",
        "\n",
        "# 5. Create the prompt for Granite\n",
        "prompt = f\"\"\"\n",
        "You are given a sample of the SMS Spam Collection dataset. Each message is labeled as either 'ham' (normal) or 'spam'.\n",
        "\n",
        "Your tasks:\n",
        "1. Analyze the content and distribution of spam and ham messages in this sample.\n",
        "2. Identify patterns, keywords, or linguistic features that differentiate spam from ham based on the sample.\n",
        "3. Generate analytical results such as common spam words, length differences, frequency trends, etc. from the sample.\n",
        "4. Share insights that explain the nature of the spam content observed in the sample.\n",
        "5. Recommend strategies to filter or manage spam effectively based on your analysis of the sample.\n",
        "\n",
        "Here is the data sample:\n",
        "{formatted_messages}\n",
        "\"\"\"\n",
        "\n",
        "# 6. Send the prompt to Granite\n",
        "response = output.invoke(prompt)\n",
        "\n",
        "# 7. Print the result\n",
        "print(\"Granite Model Response:\\n\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9_hYZWziFMN",
        "outputId": "eddc5474-404e-4482-d956-d4c72db64739"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Granite Model Response:\n",
            "\n",
            "1. **Content and Distribution Analysis:**\n",
            "\n",
            "The provided sample consists of 552 SMS messages, with 287 labeled as 'ham' (normal, non-spam) and 265 labeled as 'spam'. This indicates a relatively high proportion of spam messages (48%) compared to normal messages (52%). \n",
            "\n",
            "2. **Patterns, Keywords, and Linguistic Features:**\n",
            "\n",
            "- **Urgency and Prizes:** Spam messages often contain urgent language, promising immediate rewards such as prizes, cash, or free gifts (e.g., \"URGENT! Your Mobile No was awarded a £2,000 prize GUARANTEED. Call 09061790125 from landline. Claim 3030. Valid 12hrs only 150ppm\").\n",
            "\n",
            "- **Sexual Innuendo or Explicit Content:** Many spam messages contain explicit or sexually suggestive language, attempting to lure recipients into premium-rate services (e.g., \"Hey you can pay. With salary de. Only £...\").\n",
            "\n",
            "- **Miscellaneous Offers:** A variety of unrelated offers are included in spam messages, such as job offers, ringtones, and horoscopes (e.g., \"Join the UK's horniest Dogging service and u can have sex 2nite!\").\n",
            "\n",
            "- **Non-Standard Language:** Spam messages frequently use non-standard spelling, punctuation, and abbreviations (e.g., \"Lol or I could just starve and lose a pound by the end of the day.\").\n",
            "\n",
            "- **Lack of Personalization:** Unlike ham messages, which often contain personal details or context, spam messages tend to be generic and impersonal (e.g., \"Congrats ur awarded either a yrs supply of CDs from Virgin Records or a Mystery Gift GUARANTEED Call 09061104283 Ts&Cs www.smsco.net £1.50pm approx 3mins\").\n",
            "\n",
            "3. **Analytical Results:**\n",
            "\n",
            "- **Common Spam Words:** 'prize', 'win', 'cash', 'free', 'claim', 'urgent', 'call now', 'txt', '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Set seed agar hasil sampling selalu sama\n",
        "random.seed(42)\n",
        "\n",
        "# 1. Baca file sebagai teks\n",
        "with open('/content/spam.csv', 'r', encoding='latin-1') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# 2. Ambil 150 pesan secara acak dari seluruh baris\n",
        "sampled_lines = random.sample(lines, 150)\n",
        "\n",
        "# 3. Format setiap pesan dengan panjang maksimal 150 karakter\n",
        "max_len = 150\n",
        "formatted_messages = \"\"\n",
        "for i, line in enumerate(sampled_lines):\n",
        "    message = line.strip()\n",
        "    if message:\n",
        "        truncated = message[:max_len] + (\"...\" if len(message) > max_len else \"\")\n",
        "        formatted_messages += f\"Message {i+1}: {truncated}\\n\"\n",
        "\n",
        "# 4. Buat prompt untuk dikirim ke Granite\n",
        "prompt = f\"\"\"\n",
        "You are analyzing SMS messages that may contain spam. Each line below is a truncated message (max 150 chars), no labels provided.\n",
        "\n",
        "Your tasks:\n",
        "1. Detect patterns that could indicate spam vs non-spam (keywords, structure, tone).\n",
        "2. Generate insights from the message content (frequency of promos, length, tone).\n",
        "3. Provide analytical results based on the sample data.\n",
        "4. Suggest recommendations to detect or filter spam automatically.\n",
        "\n",
        "Here is the data:\n",
        "{formatted_messages}\n",
        "\"\"\"\n",
        "\n",
        "# 5. Kirim ke Granite\n",
        "response = output.invoke(prompt)\n",
        "\n",
        "# 6. Tampilkan hasil dari Granite\n",
        "print(\"Granite Model Response:\\n\")\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_FYhhzQp0vQ",
        "outputId": "08afad16-0f68-4b38-ae69-73306569a2c1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Granite Model Response:\n",
            "\n",
            "1. Patterns Indicating Spam vs Non-Spam:\n",
            "\n",
            "   - Spam: Often includes promotional content, unsolicited offers, excessive punctuation, abbreviations, or numbers (like phone numbers or offer codes). They may also have a high frequency of certain keywords such as \"free,\" \"win,\" \"offer,\" \"claim,\" \"text now,\" \"stop,\" etc.\n",
            "\n",
            "   - Non-Spam: Generally, more personal, less promotional, and written in standard English with proper grammar and punctuation. They often ask questions or express personal thoughts or feelings.\n",
            "\n",
            "2. Insights from Message Content:\n",
            "\n",
            "   - Frequency of Promos: There are several messages (e.g., Messages 18, 19, 28, 34, 55, 94, 95, 96, 104, 115, 124, 135) that contain promotions or offers, suggesting a high frequency of promotional content in spam messages.\n",
            "\n",
            "   - Length: Spam messages tend to be shorter and more concise, often using abbreviations and numbers. Non-spam messages are generally longer and more detailed.\n",
            "\n",
            "   - Tone: Spam messages often have a pushy or urgent tone, using phrases like \"Call now,\" \"Text now,\" \"Claim now,\" or \"Limited time offer.\" Non-spam messages are more conversational and personal.\n",
            "\n",
            "3. Analytical Results:\n",
            "\n",
            "   - Spam messages often contain promotional offers, are shorter, and use a pushy or urgent tone. They frequently include numbers or codes that could be related to offers or contests.\n",
            "\n",
            "   - Non-spam messages are typically longer, more personal, and written in standard English. They often ask questions or express personal thoughts or feelings.\n",
            "\n",
            "4. Recommendations for Automatic Spam Detection:\n",
            "\n",
            "   - Keyword Filtering: Develop a list of common spam keywords (e.g., \"free,\" \"win,\" \"offer,\" \"claim,\" \"text now,\" \"stop,\" etc.) and flag messages containing a high frequency of these.\n",
            "\n",
            "   - Pattern Recognition: Implement algorithms to identify common spam patterns, such as excessive use of numbers, abbreviations, or punctuation.\n",
            "\n",
            "   - Machine Learning: Use machine learning techniques to train a model on a dataset of labeled spam and non-spam messages. This model can then predict whether new, unseen messages are spam or not\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_lines = random.sample(lines, 500)\n",
        "\n",
        "max_len = 150\n",
        "formatted_messages = \"\"\n",
        "for i, line in enumerate(sampled_lines):\n",
        "    message = line.strip()\n",
        "    if message:\n",
        "        truncated = message[:max_len] + (\"...\" if len(message) > max_len else \"\")\n",
        "        formatted_messages += f\"Message {i+1}: {truncated}\\n\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "You are analyzing SMS messages that may contain spam. Each line below is a truncated message (max 150 chars), no labels provided.\n",
        "\n",
        "Your tasks:\n",
        "1. Detect patterns that could indicate spam vs non-spam (keywords, structure, tone).\n",
        "2. Generate insights from the message content (frequency of promos, length, tone).\n",
        "3. Provide analytical results based on the sample data.\n",
        "4. Suggest recommendations to detect or filter spam automatically.\n",
        "\n",
        "Here is the data:\n",
        "{formatted_messages}\n",
        "\"\"\"\n",
        "\n",
        "response = output.invoke(prompt)\n",
        "print(\"Granite Model Response:\\n\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5i4rXhm3sAV2",
        "outputId": "d0cf16b2-aca3-4c8f-ac6a-efc02ffd6812"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Granite Model Response:\n",
            "\n",
            "1. **Spam vs Non-Spam Patterns**:\n",
            "   - **Spam Indicators**:\n",
            "     - Use of premium rate numbers (e.g., 0906, 0871) for prize claims, horoscopes, or dating services.\n",
            "     - Vague or generic greetings (e.g., \"Dear 0776xxxxxxx\", \"Hi baby\").\n",
            "     - Promises of prizes, discounts, or special offers without a clear context or personalization.\n",
            "     - Use of excessive punctuation (!;;), abbreviations, or non-standard spellings (e.g., \"wun\", \"dun\").\n",
            "     - Lack of personal context or coherence in the message.\n",
            "     - Use of urgent or threatening language (e.g., \"URGENT\", \"YOU'RE LATE\", \"YOU'RE BEING CONTACTED\").\n",
            "   - **Non-Spam Indicators**:\n",
            "     - Personalized greetings or context (e.g., mentioning specific events, places, or shared history).\n",
            "     - Clear, coherent, and grammatically correct language.\n",
            "     - Use of standard English spelling and punctuation.\n",
            "     - Messages related to everyday activities, such as arranging meetups, discussing work, or sharing personal updates.\n",
            "\n",
            "2. **Insights from Message Content**:\n",
            "   - **Frequency of Promos**: There are numerous messages promising prizes, discounts, or special offers, often using premium rate numbers.\n",
            "   - **Length**: The messages vary greatly in length, from very short (e.g., \"Lol\") to longer, more detailed messages.\n",
            "   - **Tone**: The tone ranges from casual and friendly (e.g., \"Good morning princess!\") to urgent or threatening (e.g., \"URGENT This is our 2nd attempt to contact U\").\n",
            "   - **Personalization**: Non-spam messages tend to be more personalized, mentioning specific people, places, or events, while spam messages often lack this context.\n",
            "\n",
            "3. **Analytical Results**:\n",
            "   - The dataset contains a mix of personal and spam messages, with a noticeable prevalence of spam messages, particularly those promising prizes or using premium rate numbers.\n",
            "   - Personal messages tend to be more grammatically correct, contextually relevant, and personalized.\n",
            "   - Spam\n"
          ]
        }
      ]
    }
  ]
}